# Precision-Guided Adversarial Attack

The official repository for Precision-Guided Adversarial Attack (PG-Attack).
**First-Place in the CVPR 2024 Workshop Challenge: Black-box Adversarial Attacks on Vision Foundation Models** 

Paper: *PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving* (https://arxiv.org/abs/2407.13111)

Jiyuan Fu, Zhaoyu Chen, Kaixun Jiang, Haijing Guo, Shuyong Gao, Wenqiang Zhang

Please consider citing our paper if you find it interesting or helpful to your research.

```
@article{fu2024pgattack,
  title={PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving}, 
  author={Jiyuan Fu and Zhaoyu Chen and Kaixun Jiang and Haijing Guo and Shuyong Gao and Wenqiang Zhang},
  journal={arXiv preprint arXiv:2407.13111},
  year={2024}
}
```

## License

The project is **only free for academic research purposes** but has **no authorization for commerce**. 
