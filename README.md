# Precision-Guided Adversarial Attack

The official repository for Precision-Guided Adversarial Attack (PG-Attack).

**First-Place in the CVPR 2024 Workshop Challenge: Black-box Adversarial Attacks on Vision Foundation Models** 


Paper: *PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving* (https://arxiv.org/abs/2407.13111)

## Framework
<p align="left">
    <img src="./imgs/pipeline.png" width=83%\>
</p>


## Visualization
<p align="left">
    <img src="./imgs/vis.png" width=83%\>
</p>

## Citation
If you find our paper interesting or helpful to your research, please consider citing it, and feel free to contact fujy23@m.fudan.edu.cn if you have any questions.
```
@article{fu2024pgattack,
  title={PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving}, 
  author={Jiyuan Fu and Zhaoyu Chen and Kaixun Jiang and Haijing Guo and Shuyong Gao and Wenqiang Zhang},
  journal={arXiv preprint arXiv:2407.13111},
  year={2024}
}
```

## License

The project is **only free for academic research purposes** but has **no authorization for commerce**. 
